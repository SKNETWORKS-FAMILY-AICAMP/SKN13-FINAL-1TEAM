{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfef943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DB1 DB ì²˜ë¦¬ ì‹œì‘ ---\n",
      "âœ”ï¸ ì´ ë¡œë“œëœ PDF ë¬¸ì„œ ìˆ˜: 2172ê°œ\n",
      "âœ”ï¸ ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜: 6067ê°œ\n",
      "âœ¨ ê¸°ì¡´ DB1 DB ë¡œë“œ ì¤‘...\n",
      "ğŸš€ DB1 DBì— ì²­í¬ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤ (ì´ 6067ê°œ)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DB1 ì²­í¬ ì‚½ì…: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [03:11<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DB1 ë²¡í„° DB ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ â†’ ./vector_db/db1_regulation\n",
      "\n",
      "--- DB2 DB ì²˜ë¦¬ ì‹œì‘ ---\n",
      "MuPDF error: syntax error: invalid key in dict\n",
      "\n",
      "MuPDF error: syntax error: invalid key in dict\n",
      "\n",
      "âœ”ï¸ ì´ ë¡œë“œëœ PDF ë¬¸ì„œ ìˆ˜: 4794ê°œ\n",
      "âœ”ï¸ ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜: 9378ê°œ\n",
      "âœ¨ ê¸°ì¡´ DB2 DB ë¡œë“œ ì¤‘...\n",
      "ğŸš€ DB2 DBì— ì²­í¬ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤ (ì´ 9378ê°œ)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DB2 ì²­í¬ ì‚½ì…: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [05:00<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DB2 ë²¡í„° DB ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ â†’ ./vector_db/db2_internal\n",
      "\n",
      "--- ëª¨ë“  ë²¡í„° DB ì²˜ë¦¬ ì™„ë£Œ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm # ì§„í–‰ ìƒí™© ë°”ë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì˜ˆ: OpenAI API í‚¤)\n",
    "load_dotenv()\n",
    "\n",
    "# --- ì„¤ì • (Configuration) ---\n",
    "# OpenAI ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "# \"text-embedding-3-large\"ëŠ” ê³ í’ˆì§ˆì˜ ì„ë² ë”©ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "# chunk_size: ê° í…ìŠ¤íŠ¸ ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
    "# chunk_overlap: ì¸ì ‘í•œ ì²­í¬ ê°„ì˜ ì¤‘ë³µ ë¬¸ì ìˆ˜ (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ì— ë„ì›€)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "# ë²¡í„° DB ì €ì¥ ê²½ë¡œ ë° ëŒ€ìƒ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "# name: ê° DBì˜ ì‹ë³„ ì´ë¦„\n",
    "# path: ì›ë³¸ PDF íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ (í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨)\n",
    "# persist_path: ìƒì„±ë  Chroma ë²¡í„° DBê°€ ì €ì¥ë  ê²½ë¡œ\n",
    "targets = [\n",
    "    {\"name\": \"DB1\", \"path\": r\"C:\\skn13\\final\\DB1\", \"persist_path\": \"./vector_db/db1_regulation\"},\n",
    "    {\"name\": \"DB2\", \"path\": r\"C:\\skn13\\final\\DB2\", \"persist_path\": \"./vector_db/db2_internal\"}\n",
    "]\n",
    "\n",
    "# ë²¡í„° ì‚½ì… ì‹œ ì‚¬ìš©í•  ë°°ì¹˜(Batch) í¬ê¸°\n",
    "# ë„ˆë¬´ í¬ë©´ ë©”ëª¨ë¦¬ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆê³ , ë„ˆë¬´ ì‘ìœ¼ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# 50~200 ì‚¬ì´ì—ì„œ ì¡°ì ˆí•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.\n",
    "BATCH_SIZE = 100 \n",
    "\n",
    "# --- ì£¼ ì²˜ë¦¬ ë¡œì§ (Main Processing Logic) ---\n",
    "for target in targets:\n",
    "    print(f\"\\n--- {target['name']} DB ì²˜ë¦¬ ì‹œì‘ ---\")\n",
    "\n",
    "    # 1. PDF ë¬¸ì„œ ë¡œë“œ\n",
    "    # os.walkë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ê²½ë¡œ ë‚´ì˜ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ê¹Œì§€ íƒìƒ‰í•˜ì—¬ PDF íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    docs = []\n",
    "    for root, _, files in os.walk(target[\"path\"]):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    loader = PyMuPDFLoader(full_path)\n",
    "                    docs.extend(loader.load())\n",
    "                except Exception as e:\n",
    "                    # PDF ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ì‹œì§€ ì¶œë ¥\n",
    "                    print(f\"âš ï¸ ë¬¸ì„œ ë¡œë”© ì‹¤íŒ¨: {full_path} â†’ {e}\")\n",
    "\n",
    "    print(f\"âœ”ï¸ ì´ ë¡œë“œëœ PDF ë¬¸ì„œ ìˆ˜: {len(docs)}ê°œ\")\n",
    "    if not docs:\n",
    "        print(\"ğŸ’¡ ë¡œë“œí•  PDF ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ DBë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\")\n",
    "        continue # ë¬¸ì„œê°€ ì—†ìœ¼ë©´ í˜„ì¬ DB ì²˜ë¦¬ë¥¼ ê±´ë„ˆë›°ê³  ë‹¤ìŒ DBë¡œ ì´ë™\n",
    "\n",
    "    # 2. ë¡œë“œëœ ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• \n",
    "    chunks = splitter.split_documents(docs)\n",
    "    # ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ” ì²­í¬ ì œê±° (ê°„í˜¹ ë°œìƒí•  ìˆ˜ ìˆìŒ)\n",
    "    chunks = [doc for doc in chunks if doc.page_content.strip()]\n",
    "    print(f\"âœ”ï¸ ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ\")\n",
    "    \n",
    "    if not chunks:\n",
    "        print(\"ğŸ’¡ ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ DBë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\")\n",
    "        continue # ì²­í¬ê°€ ì—†ìœ¼ë©´ í˜„ì¬ DB ì²˜ë¦¬ë¥¼ ê±´ë„ˆë›°ê³  ë‹¤ìŒ DBë¡œ ì´ë™\n",
    "\n",
    "    # 3. Chroma DB ì´ˆê¸°í™” ë˜ëŠ” ë¡œë“œ\n",
    "    # persist_directory ê²½ë¡œì— íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ê¸°ì¡´ DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ Chroma DB ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    # ì£¼ì˜: Chroma.from_documents()ëŠ” ê¸°ì¡´ ë°ì´í„°ë¥¼ ë®ì–´ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    # ì—¬ê¸°ì„œëŠ” Chroma ê°ì²´ë¥¼ ë¨¼ì € ìƒì„±í•˜ê³  add_textsë¡œ ì²­í¬ë¥¼ ì¶”ê°€í•˜ì—¬ ê¸°ì¡´ ë°ì´í„°ì— ë³‘í•©í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    if os.path.exists(target[\"persist_path\"]) and len(os.listdir(target[\"persist_path\"])) > 0:\n",
    "        print(f\"âœ¨ ê¸°ì¡´ {target['name']} DB ë¡œë“œ ì¤‘...\")\n",
    "        vectorstore = Chroma(\n",
    "            collection_name=target[\"name\"], # ì»¬ë ‰ì…˜ ì´ë¦„ ì§€ì • (ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ ìœ ìš©)\n",
    "            embedding_function=embedding_model, # ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì§€ì •\n",
    "            persist_directory=target[\"persist_path\"] # DBê°€ ì €ì¥ëœ/ì €ì¥ë  ë””ë ‰í† ë¦¬\n",
    "        )\n",
    "    else:\n",
    "        print(f\"âœ¨ ìƒˆë¡œìš´ {target['name']} DB ìƒì„± ì¤‘...\")\n",
    "        vectorstore = Chroma(\n",
    "            collection_name=target[\"name\"],\n",
    "            embedding_function=embedding_model,\n",
    "            persist_directory=target[\"persist_path\"]\n",
    "        )\n",
    "        \n",
    "    # 4. ë¶„í• ëœ ì²­í¬ë¥¼ Chroma DBì— ë°°ì¹˜(Batch)ë¡œ ì‚½ì…\n",
    "    print(f\"ğŸš€ {target['name']} DBì— ì²­í¬ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤ (ì´ {len(chunks)}ê°œ)...\")\n",
    "    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì²­í¬ ì‚½ì… ì§„í–‰ ìƒí™©ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "    for i in tqdm(range(0, len(chunks), BATCH_SIZE), desc=f\"{target['name']} ì²­í¬ ì‚½ì…\"):\n",
    "        batch = chunks[i:i + BATCH_SIZE] # í˜„ì¬ ë°°ì¹˜ì— í•´ë‹¹í•˜ëŠ” ì²­í¬ë¥¼ ì¶”ì¶œ\n",
    "        texts = [doc.page_content for doc in batch] # ì²­í¬ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©ë§Œ ì¶”ì¶œ\n",
    "        metadatas = [doc.metadata for doc in batch] # ì²­í¬ì˜ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
    "\n",
    "        try:\n",
    "            # Chroma DBì— í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ê°€\n",
    "            vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
    "        except Exception as e:\n",
    "            # ë²¡í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ì‹œì§€ ì¶œë ¥\n",
    "            print(f\"âŒ ë²¡í„° ì‚½ì… ì‹¤íŒ¨ (ë°°ì¹˜ {i // BATCH_SIZE}): {e}\")\n",
    "\n",
    "    print(f\"âœ… {target['name']} ë²¡í„° DB ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ â†’ {target['persist_path']}\")\n",
    "\n",
    "print(\"\\n--- ëª¨ë“  ë²¡í„° DB ì²˜ë¦¬ ì™„ë£Œ ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
