import os
import re
import json
import pandas as pd
from typing import List, Dict
from collections import defaultdict
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

BASE_DIR = r"C:\Users\jhwoo\Desktop\SKN_ws\project\SKN13-FINAL-1TEAM"
SUBFOLDERS = ["ì‚¬ë‚´ê·œì •"]
CSV_FILE = r"C:\Users\jhwoo\Desktop\SKN_ws\project\SKN13-FINAL-1TEAM\ì‚¬ë‚´ê·œì •.csv"

def collect_csv_files(base_dir, subfolders):
    csvs = []
    for sub in subfolders:
        sub_path = os.path.join(base_dir, sub)
        for root, _, files in os.walk(sub_path):
            for f in files:
                if f.lower().endswith(".csv"):
                    csvs.append(os.path.join(root, f))
    return csvs

def clean_text(text: str) -> str:
    text = re.sub(r'-\s*\d+\s*-', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def build_graph_from_csv(df: pd.DataFrame, title: str) -> Dict[str, Dict[str, List[str]]]:
    # CSVìš© ê·¸ë˜í”„ êµ¬ì¡°ëŠ” ë°ì´í„°ì…‹ íŠ¹ì„±ì— ë”°ë¼ ë‹¬ë¼ì§
    # ì˜ˆ: íŠ¹ì • ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì¸µí™” ê°€ëŠ¥
    graph = defaultdict(list)
    # ì„ì‹œ ì˜ˆì‹œë¡œ "ì¥"ê³¼ "ì¡°"ë¼ëŠ” ì»¬ëŸ¼ ìˆë‹¤ê³  ê°€ì •
    if "ì œ Oì¥" in df.columns and "ì œ Oì¡°" in df.columns:
        for _, row in df.iterrows():
            chapter = row["ì œ Oì¥"]
            article = row["ì œ Oì¡°"]
            graph[chapter].append(article)
    return {title: dict(graph)}

def main():
    # splitter ì„¸íŒ… ë¨¼ì € í•´
    splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)

    # csv_files = collect_csv_files(BASE_DIR, SUBFOLDERS)
    csv_files = [CSV_FILE]
    print(f"ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    all_chunks: List[Document] = []
    document_graphs = {}

    for path in csv_files:
        df = pd.read_csv(path)
        title = os.path.basename(path).replace(".csv", "")
        document_graphs.update(build_graph_from_csv(df, title))

        for _, row in df.iterrows():
            text = " ".join(str(row[col]) for col in df.columns if col != "ì œ Oì¥" and col != "ì œ Oì¡°")
            text = clean_text(text)
            metadata = {
                "source": os.path.basename(path),
                "title": title,
                "category": os.path.basename(os.path.dirname(path))
            }
            doc = Document(page_content=text, metadata=metadata)

            # ğŸ”¥ ì—¬ê¸°ì„œ splitterë¡œ ìë¥¸ë‹¤
            chunks = splitter.split_documents([doc])
            all_chunks.extend(chunks)

    embedding = OpenAIEmbeddings(model="text-embedding-3-large")
    vectorstore = Chroma.from_documents(
        documents=all_chunks,
        embedding=embedding,
        persist_directory="./chroma/kobaco_csv"
    )
    # vectorstore.persist()
    print("âœ… CSV ê¸°ë°˜ ChromaDBì— ë²¡í„° ì €ì¥ ì™„ë£Œ")

    with open("kobaco_csv_graph.json", "w", encoding="utf-8") as f:
        json.dump(document_graphs, f, ensure_ascii=False, indent=2)
    print("âœ… CSV ë¬¸ì„œ êµ¬ì¡° ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    main()
